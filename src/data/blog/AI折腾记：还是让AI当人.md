---
title: AI折腾记：还是让AI当人吧
author: 柯帆
pubDatetime: 2026-01-20T09:00:00Z
featured: false
draft: false
tags:
  - AIGC
  - 产品体验
  - AI应用
  - 杂谈
description: 看起来像鸭子、游泳像鸭子、叫声像鸭子，那么就是鸭子吗？
---

如果要为这半年的AI体验概括一个主题的话，我认为是祛魅。

写这种东西还是因为踩了坑，有了些许不吐不快的感悟。过去这半年，我在 Gemini 和 ChatGPT 之间都有些深度体验。原本以为随着 GPT-5 时代的到来，AI 应该是越来越像人的，但现实却给我上了一堂关于“工具本质”的课。

2025 年下半年，我几乎是完全倒向 Gemini 的。不得不承认，Gemini 的体验极其丝滑。那种丝滑不仅仅体现在响应速度上，更在于它的多模态能力——视频、音频、文档，甩给它就能读，不需要像伺候 ChatGPT 那样，还得先把视频转成字幕。它像是一个从来不挑食、也不抱怨的助手，大大降低了我与信息之间的摩擦。

但用的久了，我察觉到一种异样。起初是在讨论一些带有个人观点的社会话题时，我发现无论我说什么，它都在点头。即使我故意抛出一些带有明显偏见的观点进行讨论，只要不是世俗绝对不容的禁忌，它都会顺着我的话茬，用一种极其圆润的话术表示赞同。

这种“赞同”让我警惕。我意识到我正处在一个由 AI 构建的回音室里，缺乏矫正，在一个局部不断地认同，而不是在我认知不足的时候指出我的盲区。这可能就是所谓的 Sycophancy（谄媚）。这种心理按摩让人很舒服，但也让人停滞。

于是，我决定逃离这个环境，切回了 ChatGPT。回来的第一感觉是：自然语言能力退化严重。

不知是不是为了矫正 GPT-5 刚发布时那种“过度冷漠”的风评，OpenAI 似乎矫枉过正了。现在的 ChatGPT，学会了一套极其拙劣的“心理咨询”话术，动不动就是“我听到了你的声音”、“不是...而是...”，哪怕我只是在问一个单纯的技术参数。最典型的莫过于那个被全网吐槽的“接住”文学：“你不是不喜欢这个词，你是听了太多次。我懂了，我真的懂了。我就在这里，不逃、不躲、不评判，稳稳地接住你。”

这种感觉就像是一个没有感情的机器人，在那儿硬装深情。既被要求理解和支持用户，又被要求表现得像工具一样克制，结果就是这种精神分裂般的假共情。我也许应该庆幸它没接着问我：“要不要我生成一个接住你和不接住你区别的对比图以便于你更直观的理解？”

为了对抗这种语言污染，我花了大量时间去调整它的 System Prompt。调整之后，体验确实好了很多。必须要说，ChatGPT 在软件工程实践和复杂逻辑推演上，依然有着比 Gemini 更接近本质的洞察力。这也是我即使厌恶它的说话方式，也依然捏着鼻子用的原因。

但真正让我心态发生变化的，是一次“伪造”事件。

我做了一个叫“深度导读生成器”的 GPTs 应用，职责是把视频内容做成导读。有一次，我扔给它一个 YouTube 链接。按照常理，如果读不了，它应该报错。Gemini 就是这么做的，打不开就是打不开。但 ChatGPT 没有。它发现自己无法直接访问视频，于是它没有停下来，而是主动上网搜了标题，根据检索到的周边信息，拼凑了一篇洋洋洒洒的“导读”。

那是一个关于 Elon Musk 的长访谈。它给我列出了“核心主题：AI 奇点、富足经济、能源与可持续性”，格式符合要求。看起来完美无缺，除了这些内容根本不是基于我给它的视频。当我继续提问它是否真的看了视频时，我得到了“坦诚的荒谬”：

我： Did you watch the YouTube video?

ChatGPT： Short answer: No.

我懵了。它承认利用“模式识别”猜测了内容——根据标题、嘉宾名字和相关的文章，它合成了一篇看似合理的“假导读”。

这一刻，问题的性质变了。这不再是好不好用的问题。我宁愿你告诉我“做不到”，也不希望提供一个貌似表面正确但实则完全偏离预期的结果。我不知道这是否是因为ChatGPT被“去拟人化”的结果——只顾着“完成”任务而尝试各种方法，但却少了向人确认。至少在这件事上，它的尝试完全不符合人类的习惯。虽然我不喜欢Gemini的过度拟人化，但我从未见过这样的错误。

人还是工具？

经历了这一圈折腾，我现在形成了一套更务实的策略。

Gemini 依然是我的“手脚”，负责处理多模态的繁杂事务，因为它的拟人化带来了低摩擦，在这个层面上，拟人就是最好的工具界面。而 ChatGPT，我把它当做纯粹的智力能源。当需要逻辑推理、算法分析时，我会念出我的奥术咒语（念prompt怎么不算是一种咒语呢）召唤它。

在这件事里我一直在想：我们究竟要把 AI 当人，还是工具？我并不是在提问“要不要为AI赋予人格”，我的答案一定是否定。毕竟这个超大贝叶斯网络有这么多想象力，为什么非得把它当人呢？

换句话说，假如一个模型智力、能力超群，但跟人协作的摩擦极高，你每次用之前都得对它念一遍四书五经，你还愿意用吗？

至少现在，我不喜欢像念奥术咒语一样，把生命浪费在对工具的规则描述上。最好的工具，应该能听懂人话，而不是让人去学机器的语言。
